{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad1c0afd-eb75-4f4f-a716-4e9c42749e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Ready to proceed with imports!\n",
      "✅ All libraries imported successfully!\n",
      "✅ All API keys configured!\n",
      "🤖 Gemini AI configured successfully!\n",
      "✅ Gemini model initialized successfully!\n",
      "✅ Enhanced NewsAPICollector class created!\n",
      "🔍 Testing API connections...\n",
      "==================================================\n",
      "✅ NewsAPI: Collected 4 articles\n",
      "📰 NewsAPI test: 4 articles\n",
      "✅ Guardian: Collected 5 articles\n",
      "🏛️ Guardian test: 5 articles\n",
      "✅ BBC News: Collected 10 articles\n",
      "✅ Reuters: Collected 0 articles\n",
      "✅ CNN: Collected 5 articles\n",
      "✅ AP News: Collected 0 articles\n",
      "📡 RSS feeds test: 15 articles\n",
      "🤖 Gemini AI test: ✅ Working\n",
      "\n",
      "✅ Total articles collected in test: 24\n",
      "🎉 API connections working! Ready to proceed.\n",
      "📰 Starting comprehensive news collection...\n",
      "============================================================\n",
      "✅ NewsAPI: Collected 18 articles\n",
      "✅ NewsAPI: Collected 19 articles\n",
      "✅ NewsAPI: Collected 19 articles\n",
      "✅ NewsAPI: Collected 19 articles\n",
      "✅ NewsAPI: Collected 19 articles\n",
      "✅ Guardian: Collected 15 articles\n",
      "✅ Guardian: Collected 15 articles\n",
      "✅ Guardian: Collected 15 articles\n",
      "✅ Guardian: Collected 15 articles\n",
      "✅ BBC News: Collected 10 articles\n",
      "✅ Reuters: Collected 0 articles\n",
      "✅ CNN: Collected 5 articles\n",
      "✅ AP News: Collected 0 articles\n",
      "\n",
      "📊 Collection Summary:\n",
      "   Total articles collected: 169\n",
      "   Unique articles after deduplication: 153\n",
      "\n",
      "📋 Sample articles:\n",
      "   1. Anything For The Right Words: OpenAI Offers ₹3.3 Crore For Content Strategy Role... (Source: NewsAPI-News18)\n",
      "   2. Severe storms in Mass. on Saturday with threats of wind damage, flooding, possib... (Source: NewsAPI-Yahoo Entertainment)\n",
      "   3. Runway for pre-election economic turnaround looks dangerously short for Luxon – ... (Source: NewsAPI-New Zealand Herald)\n",
      "✅ Enhanced ML model with Gemini integration trained\n",
      "🤖 Enhanced fake news classifier with Gemini AI ready!\n",
      "🔍 Analyzing collected articles with Gemini AI...\n",
      "============================================================\n",
      "Analyzing article 1/5...\n",
      "Analyzing article 2/5...\n",
      "Analyzing article 3/5...\n",
      "Analyzing article 4/5...\n",
      "Analyzing article 5/5...\n",
      "\n",
      "📊 Enhanced Analysis Results Summary:\n",
      "   Articles analyzed: 5\n",
      "   Combined predictions - Real: 4, Fake: 1\n",
      "\n",
      "🔍 Detailed Analysis Results:\n",
      "\n",
      "📰 Article 1: Anything For The Right Words: OpenAI Offers ₹3.3 Crore For C...\n",
      "   Source: NewsAPI-News18\n",
      "   ML Model: Real (50.8%)\n",
      "   Gemini AI: Real (Score: 70/100)\n",
      "   Combined: Real\n",
      "   Analysis: The article's claim that OpenAI is offering a $393,000 salary for a content strategist in India isn't inherently unbelievable, given the high demand f...\n",
      "\n",
      "📰 Article 2: Severe storms in Mass. on Saturday with threats of wind dama...\n",
      "   Source: NewsAPI-Yahoo Entertainment\n",
      "   ML Model: Real (50.8%)\n",
      "   Gemini AI: Fake (Score: 50/100)\n",
      "   Combined: Real\n",
      "   Analysis: The provided text snippet is highly suggestive of a news article about severe weather in Massachusetts.  However, the extremely short excerpt and the ...\n",
      "\n",
      "📰 Article 3: Runway for pre-election economic turnaround looks dangerousl...\n",
      "   Source: NewsAPI-New Zealand Herald\n",
      "   ML Model: Real (54.3%)\n",
      "   Gemini AI: Real (Score: 75/100)\n",
      "   Combined: Real\n",
      "   Analysis: ```json\n",
      "{\n",
      "  \"credibility_score\": 75,\n",
      "  \"explanation\": \"The provided text snippet suggests a legitimate news article.  The title is straightforward and...\n",
      "\n",
      "📰 Article 4: iPhone 17 Pro pre-order and release aren’t the only big Appl...\n",
      "   Source: NewsAPI-9to5Mac\n",
      "   ML Model: Fake (53.1%)\n",
      "   Gemini AI: Fake (Score: 40/100)\n",
      "   Combined: Fake\n",
      "   Analysis: The provided text snippet exhibits several warning signs of potentially unreliable reporting.  While the headline mentioning the iPhone 17 Pro is plau...\n",
      "\n",
      "📰 Article 5: Slain Journalist's Fiancée Is Expecting His Child Via Surrog...\n",
      "   Source: NewsAPI-TODAY\n",
      "   ML Model: Real (50.8%)\n",
      "   Gemini AI: Real (Score: 70/100)\n",
      "   Combined: Real\n",
      "   Analysis: The headline is sensationalized, focusing on the emotional aspects of the story.  While the core event – a journalist's death and his fiancée's subseq...\n",
      "\n",
      "============================================================\n",
      "🎉 ENHANCED SYSTEM READY!\n",
      "============================================================\n",
      "Your fake news detection system now includes:\n",
      "✅ Traditional ML models\n",
      "✅ Gemini AI analysis\n",
      "✅ Combined predictions\n",
      "✅ Detailed explanations\n",
      "✅ Fact-checking suggestions\n",
      "\n",
      "Test examples:\n",
      "🧪 Enhanced Custom Article Analysis\n",
      "==================================================\n",
      "Title: DOCTORS HATE THIS: One Simple Trick Cures Everything!\n",
      "Content Preview: This incredible discovery will shock you! Big pharma doesn't want you to know this secret that can cure any disease instantly. Scientists are amazed!...\n",
      "\n",
      "📊 Analysis Results:\n",
      "==============================\n",
      "❌ ML Model: Fake (60.9%)\n",
      "❌ Gemini AI: Fake (Score: 5/100)\n",
      "❌ Combined: Fake\n",
      "\n",
      "🤖 Gemini Analysis:\n",
      "   The article exhibits numerous red flags characteristic of fake news. The title employs sensational language ('DOCTORS HATE THIS', 'One Simple Trick Cures Everything!') and clickbait tactics to attract readers. The claim of an instant cure for 'any disease' is factually unrealistic and highly improbable.  The mention of 'Big Pharma' suppressing this information is a common conspiracy theory trope used to discredit established medicine. The lack of specific information, credible sources, or scientific evidence further undermines its credibility. The vague and hyperbolic language ('incredible discovery', 'scientists are amazed') avoids providing any concrete details. The writing style lacks professionalism and employs excessive exclamation points, which is another common characteristic of unreliable sources.\n",
      "\n",
      "⚠️ Warning Signs:\n",
      "   ['Sensational and clickbait headline', 'Unrealistic claim of a cure-all', \"Conspiracy theory language ('Big Pharma')\", 'Lack of credible sources and citations', 'Vague and hyperbolic language', 'Poor writing quality and excessive use of exclamation points', 'Absence of scientific evidence or data']\n",
      "\n",
      "💡 Recommendations:\n",
      "   ['Search for the purported cure or treatment using reputable medical databases (e.g., PubMed, clinicaltrials.gov)', 'Check for related news coverage from trusted news organizations (e.g., Reuters, Associated Press, BBC)', 'Look for scientific publications supporting the claims in peer-reviewed journals', 'Investigate the credentials and reputation of the purported discoverers or researchers', 'Be wary of websites or articles that lack transparency or clear contact information', 'Consider the overall tone and style of writing;  sensationalism and hyperbolic language are often indicators of unreliable information.']\n",
      "\n",
      "🔍 Fact-Checking Suggestions:\n",
      "   This headline and introduction scream \"scam,\" so fact-checking needs to focus on debunking the sensational claims.  Here are 5 specific fact-checking recommendations:\n",
      "\n",
      "1. **Investigate the \"Secret Cure\":**  The article claims a single cure for *any* disease.  This is immediately suspect.  Fact-checkers should attempt to identify the purported cure.  Is it a specific substance, a technique, or a device? Once identified, research its properties and effects using reputable scientific databases (PubMed, clinicaltrials.gov) and peer-reviewed journals. Search for any published studies supporting its efficacy in treating even a single disease, let alone \"everything.\" The absence of credible scientific evidence should be highlighted.\n",
      "\n",
      "2. **Scrutinize the \"Doctors Hate This\" Claim:**  The headline uses the inflammatory phrase \"Doctors Hate This.\"  This is a classic tactic to garner clicks by appealing to distrust of the medical establishment.  Fact-checkers should investigate whether any medical professionals have actually voiced opposition to this cure.  Look for credible sources (medical journals, professional organizations) that may have commented on the purported cure.  The absence of any such criticism should be presented as evidence against the claim.\n",
      "\n",
      "3. **Verify the \"Big Pharma Conspiracy\":**  The implication that \"Big Pharma\" is suppressing this cure is another red flag.  This is a common trope in health-related misinformation. Fact-checkers should attempt to identify the source of this claim.   Is it attributed to specific individuals or organizations?  Examine the source's credibility and potential bias.  Investigate if there are any actual conflicts of interest related to the alleged cure and pharmaceutical companies.  The absence of evidence supporting this conspiracy should be highlighted.\n",
      "\n",
      "4. **Analyze the Source of the Article:**  Determine who published the article and what their reputation is.  Is it a reputable news organization, a blog with a known bias, or an anonymous website?  Check the website's \"About Us\" section, look for contact information, and assess the overall quality of its other content.  A lack of transparency and unprofessional presentation should raise immediate concerns.\n",
      "\n",
      "5. **Look for Testimonials and Supporting Evidence:** The article likely contains testimonials from people claiming the cure worked. These testimonials should be treated with extreme skepticism. Fact-checkers should attempt to verify the authenticity of these testimonials. Are the individuals identified?  Is there any independent verification of their claims?  The article is also likely to lack any form of verifiable scientific evidence like clinical trial data or peer-reviewed studies supporting its claims.  This absence of evidence should be emphasized.\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "🧪 Enhanced Custom Article Analysis\n",
      "==================================================\n",
      "Title: Federal Reserve Announces Interest Rate Decision\n",
      "Content Preview: The Federal Reserve announced today its decision to maintain current interest rates following a comprehensive review of economic indicators and market...\n",
      "\n",
      "📊 Analysis Results:\n",
      "==============================\n",
      "✅ ML Model: Real (59.4%)\n",
      "✅ Gemini AI: Real (Score: 95/100)\n",
      "✅ Combined: Real\n",
      "\n",
      "🤖 Gemini Analysis:\n",
      "   The article presents a factual and straightforward report of a significant economic event.  The language is neutral and avoids sensationalism or emotional appeals. The subject matter—a Federal Reserve interest rate decision—is inherently newsworthy and verifiable. While the provided excerpt is brief, it lacks any obvious signs of fabrication or manipulation. The claim is plausible and aligns with the typical reporting on Federal Reserve announcements.\n",
      "\n",
      "💡 Recommendations:\n",
      "   ['Verify the announcement on the official Federal Reserve website.', 'Check major news outlets (e.g., Reuters, Bloomberg, Wall Street Journal, Associated Press) for corroborating reports.', 'Look for detailed analysis and explanations from reputable financial news sources to confirm the context and implications of the decision.']\n",
      "\n",
      "🔍 Fact-Checking Suggestions:\n",
      "   To fact-check the news article \"Federal Reserve Announces Interest Rate Decision,\"  focus on these specific steps:\n",
      "\n",
      "1. **Verify the Interest Rate Decision:**\n",
      "    * **Actionable Step:** Go directly to the official Federal Reserve website (federalreserve.gov). Locate the press release or statement announcing the interest rate decision.  Compare the rate stated in the article to the official announcement.  Look for any discrepancies in the rate itself, the effective date of the change (if any), or the wording used to describe the decision.\n",
      "    * **Source:** Federal Reserve Board's official website (press releases section).\n",
      "    * **Red Flag:** If the article's stated rate differs from the official source, or if the article omits crucial details from the official statement (e.g., conditions attached to the decision, future rate projections), it raises serious concerns about accuracy.\n",
      "\n",
      "\n",
      "2. **Examine the Justification – Economic Indicators and Market Conditions:**\n",
      "    * **Actionable Step:** The article mentions \"comprehensive review of economic indicators and market conditions.\" Investigate the specific indicators cited (or implied).  Check reliable sources like the Bureau of Labor Statistics (BLS) for employment data, the Bureau of Economic Analysis (BEA) for GDP growth, and the Consumer Price Index (CPI) for inflation data. Compare the article's interpretation of these indicators with the raw data and analysis from these official sources.\n",
      "    * **Source:** BLS, BEA, CPI reports;  Federal Reserve publications and economic commentaries.\n",
      "    * **Red Flag:**  If the article selectively highlights data to support a particular narrative while ignoring contradicting evidence or significant details from official reports, this indicates potential bias or misrepresentation.  Lack of specific data points mentioned also indicates a need for further investigation.\n",
      "\n",
      "\n",
      "3. **Analyze the \"Careful Consideration\" Claim:**\n",
      "    * **Actionable Step:**  The article states the decision was made \"after careful consideration.\"  Look for evidence of this careful consideration. This might involve reviewing the minutes of the Federal Open Market Committee (FOMC) meeting (released with a delay). This would reveal the discussions and rationales behind the decision.\n",
      "    * **Source:** Federal Reserve's FOMC meeting minutes, transcripts, or press conferences.  Commentary from economists and financial analysts on the FOMC decision.\n",
      "    * **Red Flag:** If the article fails to mention any specifics of the FOMC meeting or its discussions, its claim of \"careful consideration\" is unsubstantiated and requires more scrutiny.\n",
      "\n",
      "\n",
      "4. **Check for Author Bias & Potential Conflicts of Interest:**\n",
      "    * **Actionable Step:** Identify the author and publication of the news article. Research the publication's reputation and potential biases. Check the author's background for any potential conflicts of interest (e.g., financial ties to specific companies that would benefit from a particular interest rate decision).\n",
      "    * **Source:**  Publication's \"About Us\" section, media bias fact-checking websites (e.g., Media Bias/Fact Check), author's LinkedIn or biographical information.\n",
      "    * **Red Flag:**  Evidence of significant bias or undeclared conflicts of interest in the author or publication should raise caution about the objectivity and reliability of the article.\n",
      "\n",
      "\n",
      "\n",
      "By following these steps, a fact-checker can determine the accuracy and reliability of the news article's claims regarding the Federal Reserve's interest rate decision.\n",
      "\n",
      "\n",
      "🎯 You can now test your own articles using:\n",
      "test_custom_article_with_gemini(title, content, enhanced_classifier, gemini_analyzer)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXECUTION ORDER FOR FAKE NEWS DETECTION SYSTEM WITH NEWS APIs + GEMINI AI\n",
    "# Run these cells in sequence in your Jupyter Notebook\n",
    "# ============================================================================\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 1: Install Required Packages\n",
    "# ============================================================================\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_required_packages():\n",
    "    \"\"\"Install all required packages for the system\"\"\"\n",
    "    packages = [\n",
    "        'pandas', 'numpy', 'scikit-learn', 'requests', 'feedparser',\n",
    "        'textstat', 'aiohttp', 'asyncio', 'beautifulsoup4', 'matplotlib',\n",
    "        'seaborn', 'wordcloud', 'plotly', 'google-generativeai', 'tweepy', 'praw'\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "            print(f\"✅ Installed {package}\")\n",
    "        except:\n",
    "            print(f\"⚠️ {package} may already be installed or failed to install\")\n",
    "\n",
    "# Uncomment to install packages\n",
    "# install_required_packages()\n",
    "print(\"📦 Ready to proceed with imports!\")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 2: Import All Required Libraries\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import feedparser\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import re\n",
    "from textstat import flesch_reading_ease\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "import hashlib\n",
    "import warnings\n",
    "import google.generativeai as genai\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 3: Set Up API Keys (MOST IMPORTANT STEP)\n",
    "# ============================================================================\n",
    "\n",
    "# 🚨 REPLACE THESE WITH YOUR ACTUAL API KEYS 🚨\n",
    "API_KEYS = {\n",
    "    # Get from https://newsapi.org/\n",
    "    'newsapi': 'b8d94d93261a411ca41b535e3e009274',\n",
    "    \n",
    "    # Get from https://open-platform.theguardian.com/\n",
    "    'guardian': '4d490b9e-00dd-48f2-90d5-cd4b2c3b3df5',\n",
    "    \n",
    "    # Get from https://developer.nytimes.com/\n",
    "    'nytimes': 'VNUZFf7Ae15d33fCJG38DxV6lo3xb8ud',\n",
    "    \n",
    "    # Get from https://makersuite.google.com/app/apikey\n",
    "    'gemini': 'AIzaSyCrewT-FCF7vKMJyusdHy9k8xYVPv4hO7E'\n",
    "}\n",
    "\n",
    "# Validation\n",
    "missing_keys = [k for k, v in API_KEYS.items() if v == f'YOUR_{k.upper()}_API_KEY_HERE']\n",
    "if missing_keys:\n",
    "    print(f\"⚠️ Please update these API keys: {missing_keys}\")\n",
    "    print(\"🔗 Get your free API keys from:\")\n",
    "    print(\"   📰 NewsAPI: https://newsapi.org/\")\n",
    "    print(\"   🏛️ Guardian: https://open-platform.theguardian.com/\")\n",
    "    print(\"   📊 NY Times: https://developer.nytimes.com/\")\n",
    "    print(\"   🤖 Gemini AI: https://makersuite.google.com/app/apikey\")\n",
    "else:\n",
    "    print(\"✅ All API keys configured!\")\n",
    "\n",
    "# Configure Gemini AI\n",
    "if API_KEYS['gemini'] and 'YOUR_' not in API_KEYS['gemini']:\n",
    "    genai.configure(api_key=API_KEYS['gemini'])\n",
    "    print(\"🤖 Gemini AI configured successfully!\")\n",
    "else:\n",
    "    print(\"⚠️ Gemini AI not configured - some features will be limited\")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 4: Create Gemini AI Enhanced Analysis Class\n",
    "# ============================================================================\n",
    "\n",
    "class GeminiNewsAnalyzer:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.model = None\n",
    "        if api_key and 'YOUR_' not in api_key:\n",
    "            try:\n",
    "                genai.configure(api_key=api_key)\n",
    "                # Use the correct model name\n",
    "                self.model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "                print(\"✅ Gemini model initialized successfully!\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Failed to initialize Gemini: {e}\")\n",
    "\n",
    "    \n",
    "    def analyze_article_with_gemini(self, title, content):\n",
    "        \"\"\"Analyze article using Gemini AI for fake news detection\"\"\"\n",
    "        if not self.model:\n",
    "            return None\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Analyze the following news article for potential fake news characteristics. \n",
    "        Consider factors like:\n",
    "        - Sensational language and clickbait elements\n",
    "        - Lack of credible sources or citations\n",
    "        - Emotional manipulation tactics\n",
    "        - Factual inconsistencies or unrealistic claims\n",
    "        - Writing quality and professionalism\n",
    "        \n",
    "        Article Title: {title}\n",
    "        Article Content: {content[:1000]}...\n",
    "        \n",
    "        Please provide:\n",
    "        1. A credibility score from 0-100 (0=definitely fake, 100=definitely real)\n",
    "        2. A brief explanation of your analysis\n",
    "        3. Key warning signs (if any)\n",
    "        4. Recommendations for verification\n",
    "        \n",
    "        Format your response as JSON with keys: credibility_score, explanation, warning_signs, recommendations\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.model.generate_content(prompt)\n",
    "            \n",
    "            # Try to extract JSON from response\n",
    "            response_text = response.text\n",
    "            \n",
    "            # Simple JSON extraction (you might need to improve this)\n",
    "            if '{' in response_text and '}' in response_text:\n",
    "                json_start = response_text.find('{')\n",
    "                json_end = response_text.rfind('}') + 1\n",
    "                json_str = response_text[json_start:json_end]\n",
    "                try:\n",
    "                    result = json.loads(json_str)\n",
    "                    return result\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # Fallback: parse response manually\n",
    "            lines = response_text.split('\\n')\n",
    "            result = {\n",
    "                'credibility_score': 50,  # Default neutral\n",
    "                'explanation': response_text[:200],\n",
    "                'warning_signs': 'Unable to parse detailed analysis',\n",
    "                'recommendations': 'Verify through multiple sources'\n",
    "            }\n",
    "            \n",
    "            # Try to extract score\n",
    "            for line in lines:\n",
    "                if 'score' in line.lower():\n",
    "                    numbers = re.findall(r'\\d+', line)\n",
    "                    if numbers:\n",
    "                        result['credibility_score'] = int(numbers[0])\n",
    "                        break\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Gemini analysis error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_fact_check_suggestions(self, title, content):\n",
    "        \"\"\"Get fact-checking suggestions from Gemini\"\"\"\n",
    "        if not self.model:\n",
    "            return \"Gemini AI not available\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        For this news article, suggest specific fact-checking steps:\n",
    "        \n",
    "        Title: {title}\n",
    "        Content: {content[:500]}...\n",
    "        \n",
    "        Provide 3-5 specific, actionable fact-checking recommendations.\n",
    "        Focus on verifiable claims, sources to check, and red flags to investigate.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.model.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            return f\"Error getting suggestions: {e}\"\n",
    "\n",
    "# Initialize Gemini analyzer\n",
    "gemini_analyzer = GeminiNewsAnalyzer(API_KEYS['gemini'])\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 5: Create Enhanced News Data Collector Class\n",
    "# ============================================================================\n",
    "\n",
    "class NewsAPICollector:\n",
    "    def __init__(self, api_keys):\n",
    "        self.api_keys = api_keys\n",
    "        self.session = None\n",
    "        \n",
    "    def collect_from_newsapi(self, query=None, hours_back=24, max_articles=50):\n",
    "        \"\"\"Collect articles from NewsAPI\"\"\"\n",
    "        if not self.api_keys.get('newsapi') or 'YOUR_' in self.api_keys['newsapi']:\n",
    "            print(\"⚠️ NewsAPI key not configured, skipping...\")\n",
    "            return []\n",
    "            \n",
    "        url = \"https://newsapi.org/v2/everything\"\n",
    "        \n",
    "        params = {\n",
    "            'apiKey': self.api_keys['newsapi'],\n",
    "            'language': 'en',\n",
    "            'sortBy': 'publishedAt',\n",
    "            'pageSize': min(max_articles, 100)\n",
    "        }\n",
    "        \n",
    "        if query:\n",
    "            params['q'] = query\n",
    "        else:\n",
    "            # Get articles from last N hours\n",
    "            from_time = datetime.utcnow() - timedelta(hours=hours_back)\n",
    "            params['from'] = from_time.isoformat()\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            articles = []\n",
    "            if data.get('status') == 'ok':\n",
    "                for article in data.get('articles', []):\n",
    "                    if article.get('title') and article.get('content'):\n",
    "                        articles.append({\n",
    "                            'title': article['title'],\n",
    "                            'content': (article.get('description', '') + ' ' + \n",
    "                                      article.get('content', '')).strip(),\n",
    "                            'url': article['url'],\n",
    "                            'source': f\"NewsAPI-{article['source']['name']}\",\n",
    "                            'published_at': article['publishedAt'],\n",
    "                            'reliability_score': 0.7\n",
    "                        })\n",
    "            \n",
    "            print(f\"✅ NewsAPI: Collected {len(articles)} articles\")\n",
    "            return articles\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ NewsAPI Error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def collect_from_guardian(self, query=None, max_articles=50):\n",
    "        \"\"\"Collect articles from The Guardian\"\"\"\n",
    "        if not self.api_keys.get('guardian') or 'YOUR_' in self.api_keys['guardian']:\n",
    "            print(\"⚠️ Guardian API key not configured, skipping...\")\n",
    "            return []\n",
    "            \n",
    "        url = \"https://content.guardianapis.com/search\"\n",
    "        \n",
    "        params = {\n",
    "            'api-key': self.api_keys['guardian'],\n",
    "            'show-fields': 'headline,bodyText,publication',\n",
    "            'page-size': min(max_articles, 50)\n",
    "        }\n",
    "        \n",
    "        if query:\n",
    "            params['q'] = query\n",
    "            \n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            articles = []\n",
    "            if data.get('response', {}).get('status') == 'ok':\n",
    "                for article in data['response'].get('results', []):\n",
    "                    fields = article.get('fields', {})\n",
    "                    if fields.get('headline') and fields.get('bodyText'):\n",
    "                        articles.append({\n",
    "                            'title': fields['headline'],\n",
    "                            'content': fields['bodyText'][:1000],  # Limit content length\n",
    "                            'url': article['webUrl'],\n",
    "                            'source': 'The Guardian',\n",
    "                            'published_at': article['webPublicationDate'],\n",
    "                            'reliability_score': 0.9\n",
    "                        })\n",
    "            \n",
    "            print(f\"✅ Guardian: Collected {len(articles)} articles\")\n",
    "            return articles\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Guardian Error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def collect_from_rss_feeds(self):\n",
    "        \"\"\"Collect from RSS feeds\"\"\"\n",
    "        rss_sources = {\n",
    "            'BBC News': 'http://feeds.bbci.co.uk/news/rss.xml',\n",
    "            'Reuters': 'http://feeds.reuters.com/reuters/topNews',\n",
    "            'CNN': 'http://rss.cnn.com/rss/edition.rss',\n",
    "            'AP News': 'https://apnews.com/apf-topnews'\n",
    "        }\n",
    "        \n",
    "        all_articles = []\n",
    "        \n",
    "        for source_name, rss_url in rss_sources.items():\n",
    "            try:\n",
    "                feed = feedparser.parse(rss_url)\n",
    "                articles = []\n",
    "                \n",
    "                for entry in feed.entries[:10]:  # Limit to 10 per source\n",
    "                    content = ''\n",
    "                    if hasattr(entry, 'content') and entry.content:\n",
    "                        content = entry.content[0].value\n",
    "                    elif hasattr(entry, 'description'):\n",
    "                        content = entry.description\n",
    "                    elif hasattr(entry, 'summary'):\n",
    "                        content = entry.summary\n",
    "                    \n",
    "                    if entry.title and content:\n",
    "                        # Clean HTML tags\n",
    "                        content = re.sub(r'<[^>]+>', '', content)\n",
    "                        \n",
    "                        articles.append({\n",
    "                            'title': entry.title,\n",
    "                            'content': content[:800],  # Limit content\n",
    "                            'url': entry.link,\n",
    "                            'source': source_name,\n",
    "                            'published_at': getattr(entry, 'published', datetime.now().isoformat()),\n",
    "                            'reliability_score': 0.8\n",
    "                        })\n",
    "                \n",
    "                all_articles.extend(articles)\n",
    "                print(f\"✅ {source_name}: Collected {len(articles)} articles\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ {source_name} Error: {e}\")\n",
    "        \n",
    "        return all_articles\n",
    "\n",
    "print(\"✅ Enhanced NewsAPICollector class created!\")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 6: Initialize Collector and Test API Connections\n",
    "# ============================================================================\n",
    "\n",
    "# Initialize the collector\n",
    "collector = NewsAPICollector(API_KEYS)\n",
    "\n",
    "# Test API connections\n",
    "print(\"🔍 Testing API connections...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test NewsAPI with a simple query\n",
    "test_articles_newsapi = collector.collect_from_newsapi(query=\"technology\", max_articles=5)\n",
    "print(f\"📰 NewsAPI test: {len(test_articles_newsapi)} articles\")\n",
    "\n",
    "# Test Guardian API\n",
    "test_articles_guardian = collector.collect_from_guardian(query=\"science\", max_articles=5)\n",
    "print(f\"🏛️ Guardian test: {len(test_articles_guardian)} articles\")\n",
    "\n",
    "# Test RSS feeds\n",
    "test_articles_rss = collector.collect_from_rss_feeds()\n",
    "print(f\"📡 RSS feeds test: {len(test_articles_rss)} articles\")\n",
    "\n",
    "# Test Gemini AI\n",
    "if gemini_analyzer.model:\n",
    "    test_result = gemini_analyzer.analyze_article_with_gemini(\n",
    "        \"Test Article\", \n",
    "        \"This is a test article to verify Gemini AI integration.\"\n",
    "    )\n",
    "    print(f\"🤖 Gemini AI test: {'✅ Working' if test_result else '❌ Failed'}\")\n",
    "else:\n",
    "    print(\"🤖 Gemini AI test: ⚠️ Not configured\")\n",
    "\n",
    "total_test_articles = len(test_articles_newsapi) + len(test_articles_guardian) + len(test_articles_rss)\n",
    "print(f\"\\n✅ Total articles collected in test: {total_test_articles}\")\n",
    "\n",
    "if total_test_articles > 0:\n",
    "    print(\"🎉 API connections working! Ready to proceed.\")\n",
    "else:\n",
    "    print(\"⚠️ No articles collected. Please check your API keys.\")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 7: Collect Real News Data\n",
    "# ============================================================================\n",
    "\n",
    "def collect_comprehensive_news_data():\n",
    "    \"\"\"Collect comprehensive news data from all sources\"\"\"\n",
    "    print(\"📰 Starting comprehensive news collection...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    all_articles = []\n",
    "    \n",
    "    # Collect from NewsAPI with different queries\n",
    "    news_queries = ['breaking news', 'politics', 'technology', 'health', 'business']\n",
    "    for query in news_queries:\n",
    "        articles = collector.collect_from_newsapi(query=query, max_articles=20)\n",
    "        all_articles.extend(articles)\n",
    "    \n",
    "    # Collect from Guardian\n",
    "    guardian_queries = ['world news', 'science', 'environment', 'politics']\n",
    "    for query in guardian_queries:\n",
    "        articles = collector.collect_from_guardian(query=query, max_articles=15)\n",
    "        all_articles.extend(articles)\n",
    "    \n",
    "    # Collect from RSS feeds\n",
    "    rss_articles = collector.collect_from_rss_feeds()\n",
    "    all_articles.extend(rss_articles)\n",
    "    \n",
    "    # Remove duplicates based on title similarity\n",
    "    seen_titles = set()\n",
    "    unique_articles = []\n",
    "    \n",
    "    for article in all_articles:\n",
    "        title_key = article['title'].lower()[:50]  # First 50 chars\n",
    "        if title_key not in seen_titles:\n",
    "            seen_titles.add(title_key)\n",
    "            unique_articles.append(article)\n",
    "    \n",
    "    print(f\"\\n📊 Collection Summary:\")\n",
    "    print(f\"   Total articles collected: {len(all_articles)}\")\n",
    "    print(f\"   Unique articles after deduplication: {len(unique_articles)}\")\n",
    "    \n",
    "    # Convert to DataFrame for easier handling\n",
    "    df = pd.DataFrame(unique_articles)\n",
    "    \n",
    "    # Display sample\n",
    "    if not df.empty:\n",
    "        print(f\"\\n📋 Sample articles:\")\n",
    "        for i, row in df.head(3).iterrows():\n",
    "            print(f\"   {i+1}. {row['title'][:80]}... (Source: {row['source']})\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run the collection\n",
    "news_df = collect_comprehensive_news_data()\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 8: Create Enhanced ML Model with Gemini Integration\n",
    "# ============================================================================\n",
    "\n",
    "class GeminiEnhancedFakeNewsClassifier:\n",
    "    def __init__(self, gemini_analyzer):\n",
    "        self.vectorizer = None\n",
    "        self.model = None\n",
    "        self.is_trained = False\n",
    "        self.gemini_analyzer = gemini_analyzer\n",
    "    \n",
    "    def extract_features(self, texts):\n",
    "        \"\"\"Extract simple features from text\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        for text in texts:\n",
    "            feature_dict = {\n",
    "                'word_count': len(text.split()),\n",
    "                'exclamation_count': text.count('!'),\n",
    "                'caps_ratio': sum(1 for c in text if c.isupper()) / len(text) if text else 0,\n",
    "                'has_sensational_words': any(word in text.lower() for word in \n",
    "                    ['shocking', 'incredible', 'amazing', 'secret', 'revealed', 'exposed'])\n",
    "            }\n",
    "            features.append(feature_dict)\n",
    "        \n",
    "        return pd.DataFrame(features)\n",
    "    \n",
    "    def train_with_sample_data(self):\n",
    "        \"\"\"Train with sample fake/real news data\"\"\"\n",
    "        # Sample training data (you would replace this with your collected data)\n",
    "        fake_samples = [\n",
    "            \"SHOCKING: You won't believe this incredible secret that doctors don't want you to know!\",\n",
    "            \"BREAKING: Amazing discovery that will change everything! Big pharma HATES this!\",\n",
    "            \"INCREDIBLE: This one weird trick will shock you! Everyone is talking about it!\",\n",
    "            \"EXPOSED: The truth they don't want you to see! Share before it's deleted!\"\n",
    "        ]\n",
    "        \n",
    "        real_samples = [\n",
    "            \"The Federal Reserve announced interest rate changes following economic indicators.\",\n",
    "            \"Scientists published research findings in peer-reviewed journal Nature.\",\n",
    "            \"Local government approved infrastructure budget for upcoming fiscal year.\",\n",
    "            \"Technology company reported quarterly earnings exceeding analyst expectations.\"\n",
    "        ]\n",
    "        \n",
    "        # Combine data\n",
    "        all_texts = fake_samples + real_samples\n",
    "        labels = [1] * len(fake_samples) + [0] * len(real_samples)  # 1=Fake, 0=Real\n",
    "        \n",
    "        # Create TF-IDF features\n",
    "        self.vectorizer = TfidfVectorizer(max_features=100, stop_words='english')\n",
    "        tfidf_features = self.vectorizer.fit_transform(all_texts).toarray()\n",
    "        \n",
    "        # Train simple model\n",
    "        self.model = LogisticRegression(random_state=42)\n",
    "        self.model.fit(tfidf_features, labels)\n",
    "        self.is_trained = True\n",
    "        \n",
    "        print(\"✅ Enhanced ML model with Gemini integration trained\")\n",
    "    \n",
    "    def predict_article(self, title, content):\n",
    "        \"\"\"Enhanced prediction using both ML model and Gemini AI\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        # Traditional ML prediction\n",
    "        if self.is_trained:\n",
    "            text = f\"{title} {content}\"\n",
    "            tfidf_features = self.vectorizer.transform([text]).toarray()\n",
    "            ml_prediction = self.model.predict(tfidf_features)[0]\n",
    "            ml_confidence = max(self.model.predict_proba(tfidf_features)[0])\n",
    "            \n",
    "            results['ml_prediction'] = 'Fake' if ml_prediction == 1 else 'Real'\n",
    "            results['ml_confidence'] = ml_confidence\n",
    "        \n",
    "        # Gemini AI analysis\n",
    "        if self.gemini_analyzer.model:\n",
    "            gemini_result = self.gemini_analyzer.analyze_article_with_gemini(title, content)\n",
    "            if gemini_result:\n",
    "                results['gemini_credibility'] = gemini_result.get('credibility_score', 50)\n",
    "                results['gemini_explanation'] = gemini_result.get('explanation', '')\n",
    "                results['warning_signs'] = gemini_result.get('warning_signs', '')\n",
    "                results['recommendations'] = gemini_result.get('recommendations', '')\n",
    "                \n",
    "                # Convert Gemini score to prediction\n",
    "                results['gemini_prediction'] = 'Real' if gemini_result.get('credibility_score', 50) >= 60 else 'Fake'\n",
    "        \n",
    "        # Combined prediction\n",
    "        if 'ml_prediction' in results and 'gemini_prediction' in results:\n",
    "            # Simple voting mechanism\n",
    "            ml_vote = 1 if results['ml_prediction'] == 'Real' else 0\n",
    "            gemini_vote = 1 if results['gemini_prediction'] == 'Real' else 0\n",
    "            \n",
    "            combined_score = (ml_vote + gemini_vote) / 2\n",
    "            results['combined_prediction'] = 'Real' if combined_score >= 0.5 else 'Fake'\n",
    "            results['combined_confidence'] = combined_score\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Initialize and train the enhanced classifier\n",
    "enhanced_classifier = GeminiEnhancedFakeNewsClassifier(gemini_analyzer)\n",
    "enhanced_classifier.train_with_sample_data()\n",
    "\n",
    "print(\"🤖 Enhanced fake news classifier with Gemini AI ready!\")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 9: Analyze Collected News Articles with Gemini\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_articles_with_gemini(df, classifier):\n",
    "    \"\"\"Analyze articles using both ML and Gemini AI\"\"\"\n",
    "    if df.empty:\n",
    "        print(\"⚠️ No articles to analyze!\")\n",
    "        return None\n",
    "    \n",
    "    print(\"🔍 Analyzing collected articles with Gemini AI...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Analyze only first 5 articles to avoid rate limits\n",
    "    sample_df = df.head(5)\n",
    "    \n",
    "    for idx, row in sample_df.iterrows():\n",
    "        print(f\"Analyzing article {idx + 1}/5...\")\n",
    "        \n",
    "        # Enhanced prediction with Gemini\n",
    "        prediction = classifier.predict_article(row['title'], row['content'])\n",
    "        \n",
    "        if prediction:\n",
    "            result = {\n",
    "                'title': row['title'],\n",
    "                'source': row['source'],\n",
    "                'url': row['url'],\n",
    "                'ml_prediction': prediction.get('ml_prediction', 'N/A'),\n",
    "                'ml_confidence': prediction.get('ml_confidence', 0),\n",
    "                'gemini_prediction': prediction.get('gemini_prediction', 'N/A'),\n",
    "                'gemini_credibility': prediction.get('gemini_credibility', 0),\n",
    "                'combined_prediction': prediction.get('combined_prediction', 'N/A'),\n",
    "                'gemini_explanation': prediction.get('gemini_explanation', '')[:200],\n",
    "                'warning_signs': prediction.get('warning_signs', ''),\n",
    "                'recommendations': prediction.get('recommendations', '')\n",
    "            }\n",
    "            results.append(result)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    if not results_df.empty:\n",
    "        print(f\"\\n📊 Enhanced Analysis Results Summary:\")\n",
    "        print(f\"   Articles analyzed: {len(results_df)}\")\n",
    "        \n",
    "        if 'combined_prediction' in results_df.columns:\n",
    "            real_count = len(results_df[results_df['combined_prediction'] == 'Real'])\n",
    "            fake_count = len(results_df[results_df['combined_prediction'] == 'Fake'])\n",
    "            print(f\"   Combined predictions - Real: {real_count}, Fake: {fake_count}\")\n",
    "        \n",
    "        # Show detailed results\n",
    "        print(f\"\\n🔍 Detailed Analysis Results:\")\n",
    "        for idx, row in results_df.iterrows():\n",
    "            print(f\"\\n📰 Article {idx + 1}: {row['title'][:60]}...\")\n",
    "            print(f\"   Source: {row['source']}\")\n",
    "            if row['ml_prediction'] != 'N/A':\n",
    "                print(f\"   ML Model: {row['ml_prediction']} ({row['ml_confidence']:.1%})\")\n",
    "            if row['gemini_prediction'] != 'N/A':\n",
    "                print(f\"   Gemini AI: {row['gemini_prediction']} (Score: {row['gemini_credibility']}/100)\")\n",
    "            if row['combined_prediction'] != 'N/A':\n",
    "                print(f\"   Combined: {row['combined_prediction']}\")\n",
    "            if row['gemini_explanation']:\n",
    "                print(f\"   Analysis: {row['gemini_explanation'][:150]}...\")\n",
    "        \n",
    "        return results_df\n",
    "    else:\n",
    "        print(\"⚠️ No results generated!\")\n",
    "        return None\n",
    "\n",
    "# Run the enhanced analysis\n",
    "if not news_df.empty:\n",
    "    enhanced_results = analyze_articles_with_gemini(news_df, enhanced_classifier)\n",
    "else:\n",
    "    print(\"⚠️ No news data to analyze. Please check your API keys and run the collection again.\")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 10: Enhanced Interactive Testing Function with Gemini\n",
    "# ============================================================================\n",
    "\n",
    "def test_custom_article_with_gemini(title, content, classifier, gemini_analyzer):\n",
    "    \"\"\"Test a custom article with both ML and Gemini AI\"\"\"\n",
    "    print(\"🧪 Enhanced Custom Article Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Content Preview: {content[:150]}...\")\n",
    "    print()\n",
    "    \n",
    "    # Get enhanced prediction\n",
    "    result = classifier.predict_article(title, content)\n",
    "    \n",
    "    if result:\n",
    "        print(\"📊 Analysis Results:\")\n",
    "        print(\"=\" * 30)\n",
    "        \n",
    "        # ML Results\n",
    "        if 'ml_prediction' in result:\n",
    "            emoji = \"✅\" if result['ml_prediction'] == 'Real' else \"❌\"\n",
    "            print(f\"{emoji} ML Model: {result['ml_prediction']} ({result['ml_confidence']:.1%})\")\n",
    "        \n",
    "        # Gemini Results\n",
    "        if 'gemini_prediction' in result:\n",
    "            emoji = \"✅\" if result['gemini_prediction'] == 'Real' else \"❌\"\n",
    "            print(f\"{emoji} Gemini AI: {result['gemini_prediction']} (Score: {result['gemini_credibility']}/100)\")\n",
    "        \n",
    "        # Combined Result\n",
    "        if 'combined_prediction' in result:\n",
    "            emoji = \"✅\" if result['combined_prediction'] == 'Real' else \"❌\"\n",
    "            print(f\"{emoji} Combined: {result['combined_prediction']}\")\n",
    "        \n",
    "        # Detailed Gemini Analysis\n",
    "        if result.get('gemini_explanation'):\n",
    "            print(f\"\\n🤖 Gemini Analysis:\")\n",
    "            print(f\"   {result['gemini_explanation']}\")\n",
    "        \n",
    "        if result.get('warning_signs'):\n",
    "            print(f\"\\n⚠️ Warning Signs:\")\n",
    "            print(f\"   {result['warning_signs']}\")\n",
    "        \n",
    "        if result.get('recommendations'):\n",
    "            print(f\"\\n💡 Recommendations:\")\n",
    "            print(f\"   {result['recommendations']}\")\n",
    "        \n",
    "        # Get fact-checking suggestions\n",
    "        suggestions = gemini_analyzer.get_fact_check_suggestions(title, content)\n",
    "        if suggestions:\n",
    "            print(f\"\\n🔍 Fact-Checking Suggestions:\")\n",
    "            print(f\"   {suggestions}\")\n",
    "    else:\n",
    "        print(\"❌ Could not analyze the article.\")\n",
    "\n",
    "# Example usage:\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎉 ENHANCED SYSTEM READY!\")\n",
    "print(\"=\"*60)\n",
    "print(\"Your fake news detection system now includes:\")\n",
    "print(\"✅ Traditional ML models\")\n",
    "print(\"✅ Gemini AI analysis\")  \n",
    "print(\"✅ Combined predictions\")\n",
    "print(\"✅ Detailed explanations\")\n",
    "print(\"✅ Fact-checking suggestions\")\n",
    "print()\n",
    "print(\"Test examples:\")\n",
    "\n",
    "# Test with a suspicious article\n",
    "test_custom_article_with_gemini(\n",
    "    \"DOCTORS HATE THIS: One Simple Trick Cures Everything!\",\n",
    "    \"This incredible discovery will shock you! Big pharma doesn't want you to know this secret that can cure any disease instantly. Scientists are amazed!\",\n",
    "    enhanced_classifier,\n",
    "    gemini_analyzer\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "\n",
    "# Test with a legitimate article\n",
    "test_custom_article_with_gemini(\n",
    "    \"Federal Reserve Announces Interest Rate Decision\",\n",
    "    \"The Federal Reserve announced today its decision to maintain current interest rates following a comprehensive review of economic indicators and market conditions. The decision was reached after careful consideration of inflation data and employment statistics.\",\n",
    "    enhanced_classifier,\n",
    "    gemini_analyzer\n",
    ")\n",
    "\n",
    "print(\"\\n🎯 You can now test your own articles using:\")\n",
    "print(\"test_custom_article_with_gemini(title, content, enhanced_classifier, gemini_analyzer)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ffe4d0-a488-4ebb-ada8-e0c7a979ba6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
